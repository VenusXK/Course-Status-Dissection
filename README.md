# 基于 `yolov5` 的学生学习状态实时分析

## 文件说明

- `yolo(run)` 内包含备份的 `yolo` 运行文件
- `conda(conf)` 内包含 `conda` 配置文件
  - `pip(20230530).txt` 内包含 `pip` 配置文件
  - `environment(20230530).yaml` 内包含 `conda` 环境
  - `command.txt` 为 `conda` 导入导出语句
- `app(prj)` 内包为安卓软件开发项目

## 项目简介

课堂上学生听课状态直接关系着教学质量，而传统的课堂教学中，由于学生数量众多，教师无法及时掌握学生的听课状态。

为此，本项目利用先进的计算机视觉和人工智能技术，设计并实现了一种在线学生学习状态监测系统，为教师实时掌握学生听课情况、及时调整教学方法提供依据，从而提高教学质量和学习效果。

系统通过YOLOv5目标检测算法对课堂中学生进行实时识别和跟踪；通过大规模图像采集，训练出高精度目标检测模型，使其能够准确地识别学生听课状态特征，并对数据进行可视化展示。

在视觉模型的基础上，设计和开发了具有实时性的学习状态监测软件，能够实时捕捉学生的学习状态并提供即时反馈，有助于教师迅速了解学生的学习情况，及时进行干预和调整教学策略。

通过移动设备自带的摄像机即可实现监控，降低系统成本，降低系统使用门槛。下一步，团队计划通过大范围人脸识别匹配学生，跟踪每个学生的学习状态，根据不同学生的学习状态提供不同的建议。

另外，计划通过姿态识别和面部情绪识别提高学习状态识别精度，通过多种识别模型共同作用于同一场景，实现高精度，更具体的课堂教学效果分析。

## 研究目的 

随着高校学生数量不断增加，教育教学质量受到广泛关注。课堂上学生听课状态直接关系着教学质量，而传统的课堂教学中，由于学生数量众多，教师无法及时掌握教室中学生的听课状态，并根据学生学习状态及时调整教学模式。

为解决该问题，本项目利用摄像头采集课堂中学生的实时视频流，通过 YOLOv5 目标检测算法等模型对学生进行实时识别和跟踪。

通过大规模图像采集，训练出高精度目标检测模型，使其能够准确地识别学生的姿势、表情和其他相关特征，以评估学生的学习状态。通过实时监测学生的学习状态，帮助教师更好地了解学生在课堂上的参与度、专注度和理解程度，使教师能够及时调整教学策略，提供个性化的辅导，从而提高教学效果。

通过大范围人脸识别匹配学生，跟踪每个学生的学习状态，根据不同学生的学习状态提供不同的建议。另外，通过姿态识别和面部情绪识别提高学习状态识别精度，通过多种识别模型共同作用于同一场景，实现高精度，更具体的课堂教学效果分析。

通过分析学生学习状态的数据，为教师提供个性化的教育支持。帮助教师根据学生的需求进行个性化的教学和辅导，提高学生的学习成绩和学习体验。识别分析出的学生个人学习的数据情况将是教师重点帮扶学生的参考依据，教师可根据其近期学习数据选择与该学生交流。教师经过与学生交流，了解学生学习效果较差的原因，并进行相应疏导和帮扶，从而整体提升班级的学习成绩。对学生个人来说，其学习效果也会有较大幅度提升，有利于个人的发展。

本项目利用最新的计算机视觉技术，特别是YOLOv5和其他目标检测算法，将其应用于教育领域。通过将先进的技术与教育相结合，推动教育科技的发展，为教育提供更多智能化、自动化的解决方案，改善教学质量和学习效果。

## 研究内容

### 数据采集

在之前收集的数据集的基础上，扩大数据集收集的范围，增加数据集数量。在争取到教师和学生同意的情况下，团队将继续收集大规模的课堂学生图像或视频数据。相对于已收集的数据集，新收集的数据集将包括学生在课堂中的不同学习状态，例如专注、分心、困惑等。在扩大数据集的同时，确保数据的多样性和代表性，涵盖不同学科、不同年级和不同教学环境下的学生。同时，为了保护学生隐私，团队将对数据进行匿名化处理。

### 数据标注

对新收集的数据进行更多纬度的标注。标注的内容包括学生的姿势、表情、眼神等与学习状态相关的特征。这些标注将为训练模型提供有监督的学习信号。此外，团队还将对数据进行预处理，如图像去噪、裁剪和调整大小等，以确保数据质量和模型训练的效果。

### 完善模型选择

在选择模型方面，鉴于YOLOv5具有轻量级和高效的特点，具有较快的检测速度和较高的准确性，团队以继续采用并优化YOLOv5目标检测算法作为基础，同时，团队将尝试使用其他大范围高精度目标检测算法，做到多模型综合目标检测系统。

### 应用人脸识别技术

目前项目只能在大范围识别学生学习状态，并给出整体学习效果数据，计划通过人脸识别技术，将应用范围缩小到识别每个人的学习状态。

使用人脸识别技术对学生进行身份验证，确保目标检测模型能够准确地识别和跟踪特定学生。在课堂开始时，系统可以通过摄像头对学生进行人脸识别，将学生与其个人信息关联起来，并在后续的学习状态监测中进行个人化的分析。

使用面部微表情识别技术可以用于识别学生的表情和情绪状态。通过分析学生面部表情的细微变化，可以推断学生的情绪状态，如兴奋、困惑、专注等。将人脸识别与目标检测相结合，可以更准确地捕捉学生情感状态的变化，并提供更个性化的教学辅导。

通过人脸识别技术，可以分析学生的眼神和面部表情，进一步判断学生的参与度和注意力水平。例如，识别学生是否在看黑板、与教师进行目光交流、与同学互动等。这些信息有助于评估学生的参与度和专注度，为教师提供有针对性的教学反馈和调整策略。

在课后，学生个人学习的数据情况将是教师重点帮扶学生的参考依据，教师可根据其近期学习数据选择是否与该学生交流，经过与学生交流，了解学生学习效果较差的原因，并进行疏导和帮扶，从而整体提升班级的学习成绩，对个人来说，其学习效果也会有较大幅度提升，有利于个人的发展。

### 应用姿态识别技术

通过姿态识别技术，可以分析学生的身体姿势和动作，如坐姿、站姿、手势等。结合目标检测技术，可以准确地识别学生的姿态，并分析学生的学习状态。例如，判断学生是否保持端正的坐姿、是否在积极参与课堂活动等。这些信息有助于评估学生的参与度和注意力水平，为教师提供有针对性的教学反馈和调整策略。

通过姿态识别技术，系统可以实现实时的学生与教师互动。例如，系统可以识别学生的手势和动作，与教师进行互动交流，回答问题或提出疑问。同时，系统可以根据学生的姿态评估学生的参与度和学习效果，并给予相应的反馈和鼓励。

## 创新点与项目特色

### 多模型共同识别

提出了一种通过多模型的共同识别作用的解决方案，通过yolo对学生的学习情况进行初步分析，并采用大范围人脸识别来匹配学生，并跟踪每个学生的学习状态，根据不同学生的学习状态提供个性化建议，以达到更好的课堂学习状态分析识别效果。

### 实时性和即时反馈

设计和开发了一款具有实时性的学习状态监测软件，通过推流模块和摄像模块的相互配合，将拍摄的实时画面推流至服务器并处理分析，将实时结果和画面呈现至界面，实现了实时捕捉学生的学习状态并提供即时反馈，教师能够迅速了解学生的学习情况，及时进行干预和调整教学策略。通过使用移动软件自带的摄像机来实现视频流获取，不仅降低了系统成本，还提高了软件的适应性。该软件有效地提高了学习状态监测的效果，使教师能够更好地指导学生。

### 支持虚拟化部署

提出了一种虚拟化部署方案，通过使用Docker和Kubernets，将YOLO运行文件及其依赖项打包为一个容器镜像，使得镜像可以在集群的任何节点上运行，通过编写Kubernetes部署文件，描述如何在集群中创建和运行YOLO容器实例，实现了虚拟化部署，使得项目具有较好的可移植性，并使得迁移部署该服务十分简单。

### 与实际教学相结合

提出了项目与实际教学相结合的方法，通过收集和分析数据，探索学习状态与学习成果之间的关联、教学策略和方法的有效性，不断优化算法和模型，提升了项目效果，实现了项目的可持续发展。
通过该方法，深入研究学习状态与学习成果的关系，从而为教育领域提供有效的指导意见。通过持续优化算法和模型，有效增强了项目的效果，保证项目长期发展。该研究方法对于改进教育实践和提高学生学习效果具有重要意义。

## 技术路线

### 系统整体技术路线

系统首先通过手机的WSLive模块捕获视频流，之后将视频流推送到Nginx服务器，之后YOLO视觉服务获取Nginx推流画面进行数据分析与处理，并将处理结果写入MySQL数据库，前端通过MPAndroidChart对数据进行可视化展示，系统整体的技术路线图如下所示：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/a531d693-629b-4c55-807f-240350219b99"/>
</div>

### YOLO架构技术路线

项目采用YOLO目标检测算法算法。目标检测算法能够在图像或视频中准确地定位和识别多个学生，YOLO开源算法与传统的目标检测方法相比具有更快的速度和更高的准确率，其在计算效率和准确性之间取得了很好的平衡，在许多计算机视觉应用中被广泛使用，该算法应用的技术路线图如下：


<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/afdf2e27-53ee-4d3e-a915-9d7d84dc03d7"/>
</div>


进行YOLO算法模型训练时，首先收集包含学生学习状态的视频数据集并对数据集进行标注，在获得教师和学生同意的情况下在授课期间进行学生学习情况的拍摄，共拍摄视频40余段，截取照片200余张，通过lable-img开源标注软件标注图像1200余框。

数据集收集后，使用收集好的视频数据集及YOLO模型的预训练模型进行模型训练，训练过程包括将视频帧输入到网络中，通过反向传播优化模型的权重和参数，最终使其能够准确地检测目标物体，在训练10余轮后，模型准确率和召回率均较高，通过模型可以得到较好效果。训练模型后，根据具体的应用场景和需求，对模型进行调优和参数设置，并设置模型识别后显示的文本框大小和颜色等属性。

### MySQL数据存储技术路线

项目采用MySQL数据库。数据库提供了一种结构化的数据存储方式，MySQL是一种开源的关系型数据库管理系统，使用SQL进行数据库管理，广泛用于各种应用开发,支持多种操作系统，提供高性能、可靠性和可伸缩性，MySQL数据库技术路线图如下：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/2fbf64c2-dc16-4cd1-944d-0032b88c923b"/>
</div>

使用MySQL数据库时，首先实现相应的数据库连接语句，创建数据库和相关表，之后在YOLO模块的推理脚本中建立与数据库的连接，并进行必要的配置，在将推理分析数据写入数据库之前，将数据进行转换格式，之后使用MySQL数据库的相关语句修改Python推理脚本，将新的分析数据添加到数据库中，数据包含听课人数数据和未听课人数数据。

### Nginx推流服务技术路线

本项目采用Nginx服务器作为推流服务器。Nginx是一款轻量级的Web 服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强，且具有丰富插件，本项目利用其推流插件，实现对视频流进行存储和拉取，Nginx推流服务器路线图如下：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/bc994a2b-bd64-4df8-a692-63f8f531827a"/>
</div>

搭建Nginx服务时，首先安装Nginx服务器并进行监听端口配置，通过设置不同监听端口配置两个独立的Nginx推流服务器实例，在计算机上同时运行两个推流中转服务。

### WSLive推流技术路线

本项目采用WSLive作为推流模块。WSLive是一种流媒体服务平台，用于实时视频和音频传输。提供了一套完整的解决方案，包括推流、拉流、转码、存储和分发等功能,实现WSLive相关功能的技术路线图如下所示：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/9aca8135-4ac4-47e5-9f17-0a41b11b8a0f"/>
</div>

开发实时软件进行集成直播推流功能时，通过开源模块WSLive将视频流传输到服务器，以便用户可以通过手机摄像头捕捉实时视频。推流功能集成后，进行推流参数设置，显示连接状态、帧率等推流状态信息。

### Android可视化技术路线

本项目采用MPAndroidChart库实现数据可视化。MPAndroidChart是一个在Android平台上用于绘制图表的开源库。它提供了丰富的图表类型，包括线形图、柱状图、饼图、雷达图和散点图等。MPAndroidChart具有灵活的配置选项，可以自定义图表的外观和交互方式，实现数据可视化的技术路线图如下：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/3718c075-6eaa-4ad5-93cb-5d14e21ec993"/>
</div>

开发软件时进行集成可视化功能时，首先通过在项目的 Gradle 文件中添加库的依赖以在Android项目中引入MPAndroidChart库。之后通过编写DBHelper类文件访问数据库并准备和转换模型推理分析的数据，使其适合于图表展示。使用MPAndroidChart库提供的 API，创建各种类型的图表视图。通过更新数据集对象，添加数据点来实现数据更新和动态展示，之后调用相应的刷新方法更新图表视图。

### 虚拟化部署技术路线

另外，本项目采用Kubernets实现项目的虚拟化部署，Kubernetes是一个开源系统，用于跨多个主机管理容器化应用程序并且提供用于部署、维护和扩展应用程序的基本机制。

进行虚拟化部署时，首先在物理或虚拟机上安装和配置 Kubernetes 集群。通过编写Dockerfile文件创建分别包含Nginx和YOLO的Docker 镜像，其中包括安装和配置Nginx，之后编写Kubernetes的配置文件，描述如何在集群中创建和运行容器。配置文件中需要指定所需的资源、容器镜像、环境变量等。使用Kubernetes的Deployment资源，定义Nginx的部署配置。通过部署配置，Kubernetes 会创建和管理多个Nginx和Yolo容器的副本。使用kubectl将容器部署到Kubernetes集群中。通过Kubernetes的服务发现功能，将流量路由到容器，实现虚拟化部署。

## 拟解决的问题

学习并使用OpenPose模型，OpenPose算法能够检测和分析人体的关键点，包括头部、肩膀、手臂、腿部等关键部位的位置和姿态。通过OpenPose算法，尝试对学生的动
作进行实时分析，例如起立、举手、写字等动作。

学习大范围高精度的人脸识别算法，和同学研讨掌握其实现可能性，了解其他大范围高精度的人脸识别项目，将技术应用到本项目中。
当前软件的推流模块使用开源项目的推流模块，计划实现ffmpeg源码的交叉编译，从而实现推流性能的优化。



