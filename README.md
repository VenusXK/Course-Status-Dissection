
- [基于 `yolov5` 的学生学习状态实时分析](#基于-yolov5-的学生学习状态实时分析)
  - [文件说明](#文件说明)
  - [项目简介](#项目简介)
  - [研究目的](#研究目的)
  - [研究内容](#研究内容)
    - [数据采集](#数据采集)
    - [数据标注](#数据标注)
    - [完善模型选择](#完善模型选择)
    - [应用人脸识别技术](#应用人脸识别技术)
    - [应用姿态识别技术](#应用姿态识别技术)
  - [创新点与项目特色](#创新点与项目特色)
    - [多模型共同识别](#多模型共同识别)
    - [实时性和即时反馈](#实时性和即时反馈)
    - [支持虚拟化部署](#支持虚拟化部署)
    - [与实际教学相结合](#与实际教学相结合)
  - [技术路线](#技术路线)
    - [系统整体技术路线](#系统整体技术路线)
    - [YOLO架构技术路线](#yolo架构技术路线)
    - [MySQL数据存储技术路线](#mysql数据存储技术路线)
    - [Nginx推流服务技术路线](#nginx推流服务技术路线)
    - [WSLive推流技术路线](#wslive推流技术路线)
    - [Android可视化技术路线](#android可视化技术路线)
    - [虚拟化部署技术路线](#虚拟化部署技术路线)
  - [拟解决的问题](#拟解决的问题)
  - [研究积累](#研究积累)
    - [整体系统架构](#整体系统架构)
    - [数据集获取](#数据集获取)
    - [数据标注与模型训练](#数据标注与模型训练)
    - [软件开发](#软件开发)
  - [已具备的条件，尚缺少的条件及解决方法](#已具备的条件尚缺少的条件及解决方法)
    - [已具备的条件：](#已具备的条件)
    - [尚缺少的条件](#尚缺少的条件)
    - [解决方法](#解决方法)


# 基于 `yolov5` 的学生学习状态实时分析

## 文件说明

- `yolo(run)` 内包含备份的 `yolo` 运行文件
- `conda(conf)` 内包含 `conda` 配置文件
  - `pip(20230530).txt` 内包含 `pip` 配置文件
  - `environment(20230530).yaml` 内包含 `conda` 环境
  - `command.txt` 为 `conda` 导入导出语句
- `app(prj)` 内包为安卓软件开发项目

## 项目简介

课堂上学生听课状态直接关系着教学质量，而传统的课堂教学中，由于学生数量众多，教师无法及时掌握学生的听课状态。

为此，本项目利用先进的计算机视觉和人工智能技术，设计并实现了一种在线学生学习状态监测系统，为教师实时掌握学生听课情况、及时调整教学方法提供依据，从而提高教学质量和学习效果。

系统通过YOLOv5目标检测算法对课堂中学生进行实时识别和跟踪；通过大规模图像采集，训练出高精度目标检测模型，使其能够准确地识别学生听课状态特征，并对数据进行可视化展示。

在视觉模型的基础上，设计和开发了具有实时性的学习状态监测软件，能够实时捕捉学生的学习状态并提供即时反馈，有助于教师迅速了解学生的学习情况，及时进行干预和调整教学策略。

通过移动设备自带的摄像机即可实现监控，降低系统成本，降低系统使用门槛。下一步，团队计划通过大范围人脸识别匹配学生，跟踪每个学生的学习状态，根据不同学生的学习状态提供不同的建议。

另外，计划通过姿态识别和面部情绪识别提高学习状态识别精度，通过多种识别模型共同作用于同一场景，实现高精度，更具体的课堂教学效果分析。

## 研究目的 

随着高校学生数量不断增加，教育教学质量受到广泛关注。课堂上学生听课状态直接关系着教学质量，而传统的课堂教学中，由于学生数量众多，教师无法及时掌握教室中学生的听课状态，并根据学生学习状态及时调整教学模式。

为解决该问题，本项目利用摄像头采集课堂中学生的实时视频流，通过 YOLOv5 目标检测算法等模型对学生进行实时识别和跟踪。

通过大规模图像采集，训练出高精度目标检测模型，使其能够准确地识别学生的姿势、表情和其他相关特征，以评估学生的学习状态。通过实时监测学生的学习状态，帮助教师更好地了解学生在课堂上的参与度、专注度和理解程度，使教师能够及时调整教学策略，提供个性化的辅导，从而提高教学效果。

通过大范围人脸识别匹配学生，跟踪每个学生的学习状态，根据不同学生的学习状态提供不同的建议。另外，通过姿态识别和面部情绪识别提高学习状态识别精度，通过多种识别模型共同作用于同一场景，实现高精度，更具体的课堂教学效果分析。

通过分析学生学习状态的数据，为教师提供个性化的教育支持。帮助教师根据学生的需求进行个性化的教学和辅导，提高学生的学习成绩和学习体验。识别分析出的学生个人学习的数据情况将是教师重点帮扶学生的参考依据，教师可根据其近期学习数据选择与该学生交流。教师经过与学生交流，了解学生学习效果较差的原因，并进行相应疏导和帮扶，从而整体提升班级的学习成绩。对学生个人来说，其学习效果也会有较大幅度提升，有利于个人的发展。

本项目利用最新的计算机视觉技术，特别是YOLOv5和其他目标检测算法，将其应用于教育领域。通过将先进的技术与教育相结合，推动教育科技的发展，为教育提供更多智能化、自动化的解决方案，改善教学质量和学习效果。

## 研究内容

### 数据采集

在之前收集的数据集的基础上，扩大数据集收集的范围，增加数据集数量。在争取到教师和学生同意的情况下，团队将继续收集大规模的课堂学生图像或视频数据。相对于已收集的数据集，新收集的数据集将包括学生在课堂中的不同学习状态，例如专注、分心、困惑等。在扩大数据集的同时，确保数据的多样性和代表性，涵盖不同学科、不同年级和不同教学环境下的学生。同时，为了保护学生隐私，团队将对数据进行匿名化处理。

### 数据标注

对新收集的数据进行更多纬度的标注。标注的内容包括学生的姿势、表情、眼神等与学习状态相关的特征。这些标注将为训练模型提供有监督的学习信号。此外，团队还将对数据进行预处理，如图像去噪、裁剪和调整大小等，以确保数据质量和模型训练的效果。

### 完善模型选择

在选择模型方面，鉴于YOLOv5具有轻量级和高效的特点，具有较快的检测速度和较高的准确性，团队以继续采用并优化YOLOv5目标检测算法作为基础，同时，团队将尝试使用其他大范围高精度目标检测算法，做到多模型综合目标检测系统。

### 应用人脸识别技术

目前项目只能在大范围识别学生学习状态，并给出整体学习效果数据，计划通过人脸识别技术，将应用范围缩小到识别每个人的学习状态。

使用人脸识别技术对学生进行身份验证，确保目标检测模型能够准确地识别和跟踪特定学生。在课堂开始时，系统可以通过摄像头对学生进行人脸识别，将学生与其个人信息关联起来，并在后续的学习状态监测中进行个人化的分析。

使用面部微表情识别技术可以用于识别学生的表情和情绪状态。通过分析学生面部表情的细微变化，可以推断学生的情绪状态，如兴奋、困惑、专注等。将人脸识别与目标检测相结合，可以更准确地捕捉学生情感状态的变化，并提供更个性化的教学辅导。

通过人脸识别技术，可以分析学生的眼神和面部表情，进一步判断学生的参与度和注意力水平。例如，识别学生是否在看黑板、与教师进行目光交流、与同学互动等。这些信息有助于评估学生的参与度和专注度，为教师提供有针对性的教学反馈和调整策略。

在课后，学生个人学习的数据情况将是教师重点帮扶学生的参考依据，教师可根据其近期学习数据选择是否与该学生交流，经过与学生交流，了解学生学习效果较差的原因，并进行疏导和帮扶，从而整体提升班级的学习成绩，对个人来说，其学习效果也会有较大幅度提升，有利于个人的发展。

### 应用姿态识别技术

通过姿态识别技术，可以分析学生的身体姿势和动作，如坐姿、站姿、手势等。结合目标检测技术，可以准确地识别学生的姿态，并分析学生的学习状态。例如，判断学生是否保持端正的坐姿、是否在积极参与课堂活动等。这些信息有助于评估学生的参与度和注意力水平，为教师提供有针对性的教学反馈和调整策略。

通过姿态识别技术，系统可以实现实时的学生与教师互动。例如，系统可以识别学生的手势和动作，与教师进行互动交流，回答问题或提出疑问。同时，系统可以根据学生的姿态评估学生的参与度和学习效果，并给予相应的反馈和鼓励。

## 创新点与项目特色

### 多模型共同识别

提出了一种通过多模型的共同识别作用的解决方案，通过yolo对学生的学习情况进行初步分析，并采用大范围人脸识别来匹配学生，并跟踪每个学生的学习状态，根据不同学生的学习状态提供个性化建议，以达到更好的课堂学习状态分析识别效果。

### 实时性和即时反馈

设计和开发了一款具有实时性的学习状态监测软件，通过推流模块和摄像模块的相互配合，将拍摄的实时画面推流至服务器并处理分析，将实时结果和画面呈现至界面，实现了实时捕捉学生的学习状态并提供即时反馈，教师能够迅速了解学生的学习情况，及时进行干预和调整教学策略。通过使用移动软件自带的摄像机来实现视频流获取，不仅降低了系统成本，还提高了软件的适应性。该软件有效地提高了学习状态监测的效果，使教师能够更好地指导学生。

### 支持虚拟化部署

提出了一种虚拟化部署方案，通过使用Docker和Kubernets，将YOLO运行文件及其依赖项打包为一个容器镜像，使得镜像可以在集群的任何节点上运行，通过编写Kubernetes部署文件，描述如何在集群中创建和运行YOLO容器实例，实现了虚拟化部署，使得项目具有较好的可移植性，并使得迁移部署该服务十分简单。

### 与实际教学相结合

提出了项目与实际教学相结合的方法，通过收集和分析数据，探索学习状态与学习成果之间的关联、教学策略和方法的有效性，不断优化算法和模型，提升了项目效果，实现了项目的可持续发展。
通过该方法，深入研究学习状态与学习成果的关系，从而为教育领域提供有效的指导意见。通过持续优化算法和模型，有效增强了项目的效果，保证项目长期发展。该研究方法对于改进教育实践和提高学生学习效果具有重要意义。

## 技术路线

### 系统整体技术路线

系统首先通过手机的WSLive模块捕获视频流，之后将视频流推送到Nginx服务器，之后YOLO视觉服务获取Nginx推流画面进行数据分析与处理，并将处理结果写入MySQL数据库，前端通过MPAndroidChart对数据进行可视化展示，系统整体的技术路线图如下所示：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/a531d693-629b-4c55-807f-240350219b99"/>
</div>

### YOLO架构技术路线

项目采用YOLO目标检测算法算法。目标检测算法能够在图像或视频中准确地定位和识别多个学生，YOLO开源算法与传统的目标检测方法相比具有更快的速度和更高的准确率，其在计算效率和准确性之间取得了很好的平衡，在许多计算机视觉应用中被广泛使用，该算法应用的技术路线图如下：


<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/afdf2e27-53ee-4d3e-a915-9d7d84dc03d7"/>
</div>


进行YOLO算法模型训练时，首先收集包含学生学习状态的视频数据集并对数据集进行标注，在获得教师和学生同意的情况下在授课期间进行学生学习情况的拍摄，共拍摄视频40余段，截取照片200余张，通过lable-img开源标注软件标注图像1200余框。

数据集收集后，使用收集好的视频数据集及YOLO模型的预训练模型进行模型训练，训练过程包括将视频帧输入到网络中，通过反向传播优化模型的权重和参数，最终使其能够准确地检测目标物体，在训练10余轮后，模型准确率和召回率均较高，通过模型可以得到较好效果。训练模型后，根据具体的应用场景和需求，对模型进行调优和参数设置，并设置模型识别后显示的文本框大小和颜色等属性。

### MySQL数据存储技术路线

项目采用MySQL数据库。数据库提供了一种结构化的数据存储方式，MySQL是一种开源的关系型数据库管理系统，使用SQL进行数据库管理，广泛用于各种应用开发,支持多种操作系统，提供高性能、可靠性和可伸缩性，MySQL数据库技术路线图如下：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/2fbf64c2-dc16-4cd1-944d-0032b88c923b"/>
</div>

使用MySQL数据库时，首先实现相应的数据库连接语句，创建数据库和相关表，之后在YOLO模块的推理脚本中建立与数据库的连接，并进行必要的配置，在将推理分析数据写入数据库之前，将数据进行转换格式，之后使用MySQL数据库的相关语句修改Python推理脚本，将新的分析数据添加到数据库中，数据包含听课人数数据和未听课人数数据。

### Nginx推流服务技术路线

本项目采用Nginx服务器作为推流服务器。Nginx是一款轻量级的Web 服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强，且具有丰富插件，本项目利用其推流插件，实现对视频流进行存储和拉取，Nginx推流服务器路线图如下：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/bc994a2b-bd64-4df8-a692-63f8f531827a"/>
</div>

搭建Nginx服务时，首先安装Nginx服务器并进行监听端口配置，通过设置不同监听端口配置两个独立的Nginx推流服务器实例，在计算机上同时运行两个推流中转服务。

### WSLive推流技术路线

本项目采用WSLive作为推流模块。WSLive是一种流媒体服务平台，用于实时视频和音频传输。提供了一套完整的解决方案，包括推流、拉流、转码、存储和分发等功能,实现WSLive相关功能的技术路线图如下所示：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/9aca8135-4ac4-47e5-9f17-0a41b11b8a0f"/>
</div>

开发实时软件进行集成直播推流功能时，通过开源模块WSLive将视频流传输到服务器，以便用户可以通过手机摄像头捕捉实时视频。推流功能集成后，进行推流参数设置，显示连接状态、帧率等推流状态信息。

### Android可视化技术路线

本项目采用MPAndroidChart库实现数据可视化。MPAndroidChart是一个在Android平台上用于绘制图表的开源库。它提供了丰富的图表类型，包括线形图、柱状图、饼图、雷达图和散点图等。MPAndroidChart具有灵活的配置选项，可以自定义图表的外观和交互方式，实现数据可视化的技术路线图如下：

<div align="center">
  <img src="https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/3718c075-6eaa-4ad5-93cb-5d14e21ec993"/>
</div>

开发软件时进行集成可视化功能时，首先通过在项目的 Gradle 文件中添加库的依赖以在Android项目中引入MPAndroidChart库。之后通过编写DBHelper类文件访问数据库并准备和转换模型推理分析的数据，使其适合于图表展示。使用MPAndroidChart库提供的 API，创建各种类型的图表视图。通过更新数据集对象，添加数据点来实现数据更新和动态展示，之后调用相应的刷新方法更新图表视图。

### 虚拟化部署技术路线

另外，本项目采用Kubernets实现项目的虚拟化部署，Kubernetes是一个开源系统，用于跨多个主机管理容器化应用程序并且提供用于部署、维护和扩展应用程序的基本机制。

进行虚拟化部署时，首先在物理或虚拟机上安装和配置 Kubernetes 集群。通过编写Dockerfile文件创建分别包含Nginx和YOLO的Docker 镜像，其中包括安装和配置Nginx，之后编写Kubernetes的配置文件，描述如何在集群中创建和运行容器。配置文件中需要指定所需的资源、容器镜像、环境变量等。使用Kubernetes的Deployment资源，定义Nginx的部署配置。通过部署配置，Kubernetes 会创建和管理多个Nginx和Yolo容器的副本。使用kubectl将容器部署到Kubernetes集群中。通过Kubernetes的服务发现功能，将流量路由到容器，实现虚拟化部署。

## 拟解决的问题

学习并使用OpenPose模型，OpenPose算法能够检测和分析人体的关键点，包括头部、肩膀、手臂、腿部等关键部位的位置和姿态。通过OpenPose算法，尝试对学生的动
作进行实时分析，例如起立、举手、写字等动作。

学习大范围高精度的人脸识别算法，和同学研讨掌握其实现可能性，了解其他大范围高精度的人脸识别项目，将技术应用到本项目中。
当前软件的推流模块使用开源项目的推流模块，计划实现ffmpeg源码的交叉编译，从而实现推流性能的优化。


## 研究积累

### 整体系统架构

整体系统架构图如下所示：

![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/755b50ef-2a67-4ec7-a908-3789c034b571)


数据层包括学生听课数据、学生未听课数据、上课时间数据和课程数据，数据存储于MySQL中，通过JDBC进行数据库访问。

运行层主要包含YOLOv5模型、MySQL数据库、WSLive组件和MPAndroidChart组件。

YOLO是一个计算机视觉算法，用于目标检测，它是一种实时目标检测算法，能够在图像或视频中准确地识别和定位多个对象。与传统的目标检测方法相比，YOLO具有更快的速度和更高的准确率，其在计算效率和准确性之间取得了很好的平衡，因此在许多计算机视觉应用中被广泛使用。

MySQL是一种开源的关系型数据库管理系统（RDBMS），它使用SQL进行数据库管理。MySQL是最流行的数据库之一，被广泛用于Web应用程序开发。它支持多种操作系统，并提供高性能、可靠性和可伸缩性。

WSLive是一种流媒体服务平台，用于实时视频和音频传输。它提供了一套完整的解决方案，包括推流、拉流、转码、存储和分发等功能，其可以用于构建实时直播、视频会议、在线教育和视频监控等应用。它支持各种流媒体协议，如RTMP、HLS和WebRTC，并提供了灵活的API和SDK，使开发者能够轻松集成和定制流媒体功能。

MPAndroidChart是一个在Android平台上用于绘制图表的开源库。它提供了丰富的图表类型，包括线形图、柱状图、饼图、雷达图和散点图等。MPAndroidChart具有灵活的配置选项，可以自定义图表的外观和交互方式。

虚拟化服务层方面，在Kubernetes下运行YOLO算法可以实现高效的分布式目标检测和识别。将YOLO算法及其依赖项打包为一个Docker容器镜像，其中包括YOLO的安装和配置过程。确保镜像可以在集群的任何节点上运行。

部署Kubernets时，首先编写一个Kubernetes部署文件，描述如何在集群中创建和运行YOLO容器实例。部署文件应指定所需的资源（例如CPU、内存）、容器镜像和环境变量等。

### 数据集获取

通过购买海康威视摄像头，在获得教师和学生同意的情况下在授课期间进行学生学习情况的拍摄，共拍摄视频40余段，截取照片200余张，通过lable-img开源标注软件标注图像1200余框，局部数据集照片截图如下：
 
![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/78d18b1e-4475-405e-90d5-8622bba672b7)

![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/ff7c560e-cae8-4bbe-99cf-7433611ad52e)

### 数据标注与模型训练

通过YOLOv5进行模型训练，并选择yolov5s.pt作为预训练模型，通过lable-img标注图像1200余框，标注文件列表如下：
 
![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/033c5480-dd48-452d-94b3-cf43c7e38578)

模型识别效果如下图所示：

![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/2a780e3c-da05-4265-ba8f-8c8b9a644a08)

### 软件开发

设计和开发具有实时性的学习状态监测软件，能够实时捕捉学生的学习状态并提供即时反馈。这有助于教师迅速了解学生的学习情况，及时进行干预和调整教学策略。通过移动软件自带的摄像机即可实现监控，降低系统成本，提高软件适应度。

产品当前设计原型如图11所示。根据设计原型实现软件各模块功能，软件最终实现效果如图12所示。

![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/63248fdd-abc2-440a-aacf-bbe84a2cee6a)

![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/9eeb0e86-024b-45de-801f-d926ec04cf84)

通过折线图直观展示课堂的听课趋势变化，使得授课教师更快获得信息。

软件启动后，获取拍摄画面，将拍摄画面向数据处理服务器推流，之后通过多线程同时运行多种功能；

- 子线程1中，一开始显示收流提示语，在点击收流按钮后，从Nginx服务器的1936端口获取框取画面，显示在相应位置；
- 子线程2中，查询数据处理服务器的MySQL数据库，通过数据绘制折线图并直接显示对比数据。

拍摄权限申请时，通过配置 AndroidManifest.xml 和动态权限申请语句申请访问用户摄像机。通过开源移动平台的全能多媒体开发框架 Vitamio 相关 API 实现摄像机的调用和画面实时获取；
实时画面显示和推流模块通过调用开源移动平台的全能多媒体开发框架 Vitamio 视频播放器，设置相关参数，将摄像头录制信息实时展示到主界面中，并将显示画面推流，通过直播开源SDK WLive组件相关 API 实现摄像画面实时推流到nginx服务器。

通过开源服务器Nginx进行rtmp服务器部署，下载rtmp相关模块包后，开放1935端口以接收移动端推流画面，开放1936端口以推流分析后的框取画面。由于在windows下未对rtmp模块进行编译，需要采用nginx Gryphon配合nginx-rtmp-module的方式搭建rtmp服务器。

实时画面处理方面，通过开源计算机视觉识别框架yolov5对Nginx服务器1935端口的视频流进行实时分析和推理，将分析后的实时听课情况数据写入本地MySQL数据库，并将分析后的框取视频流推流至Nginx服务器的1936端口。

移动应用获取分析画面方面，移动应用通过SDK WSLive开发框架的相关API获取Nginx服务器的1936端口的实时框取画面视频流，将画面通过多线程展示到页面相应区域。
 
 ![image](https://github.com/2023S3AI/Student-Learning-Status-in-Class/assets/92314675/2d85fb84-b8d8-462c-a7c4-cb184c555edb)

分析数据传输方面，移动应用通过对数据处理服务器的MySQL服务（即3306端口）进行相应查询操作，通过多线程展示到页面相应区域。Java中访问数据库部分核心为jdbc的相关API的实现。

分析数据可视化方面，通过移动端开源图表框架MPAndroidChart的相关API接口，将从数据处理服务器的MySQL服务（即3306端口）查询的结果通过多线程展示到页面相应区域。通过MPAndroidChart初始化图表主要内容为MPAndroidChart的API实现。通过MPAndroidChart更新图表主要内容为MPAndroidChart的API实现。

## 已具备的条件，尚缺少的条件及解决方法

### 已具备的条件：

实现了YOLO视觉识别算法；搭建了推流服务器；基本实现了相关软件。

### 尚缺少的条件

对OpenPose姿态识别技术的实际应用；对大范围高精度人脸识别技术的实际应用；对FFmpeg源码推流的技术实现。

### 解决方法

对于OpenPose姿态识别技术，计划通过深入学习相关的姿态估计算法和深度学习模型，例如OpenPose模型。你可以阅读论文和教程，参考开源项目进行实践，自己实现相关算法，根据项目需求对姿态识别进行应用。

对于大范围高精度人脸识别技术，计划探索先进的人脸识别算法和模型，如基于深度学习的人脸识别方法。学习卷积神经网络架构和人脸特征提取方法，例如人脸识别中常用的人脸嵌入方法等。

对于FFmpeg源码推流的技术实现，深入学习FFmpeg的源代码和相关文档，理解推流的原理和实现方式，了解视频编码、封装格式以及网络传输等相关知识。尝试编译和修改FFmpeg源码。
